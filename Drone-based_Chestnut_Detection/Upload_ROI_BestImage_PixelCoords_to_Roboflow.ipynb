{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center> Upload Best Image and Polygon Mask to Roboflow</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "import os\n",
    "import pickle\n",
    "import cv2\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import exiftool\n",
    "import pandas as pd\n",
    "import PIL\n",
    "import json\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExifTool is accessible.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check if ExifTool is accessible\n",
    "try:\n",
    "    subprocess.run([\"exiftool\", \"-ver\"], check=True)\n",
    "    print(\"ExifTool is accessible.\")\n",
    "except subprocess.CalledProcessError:\n",
    "    print(\"ExifTool is not accessible.\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working directory for IDP outputs\n",
    "dir = \"C:/Users/exx/EasyIDP/Route9_Orchard4/Outputs/\"\n",
    "\n",
    "# Path to folder containing raw UAV images\n",
    "raw_img_folder_path = \"D:/Savanna Institute Drone 2023/Route 9/Raw Images/Orchard 4/20230823_Route9-Orchard4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the folder names in \"C:\\Users\\zack\\Desktop\\easyIDP\\Route9_Orchard3\\best5_images\". Store the folder names in a list\n",
    "folder_path = dir + \"best5_images\"\n",
    "folder_names = os.listdir(folder_path)\n",
    "\n",
    "# remove non integer names from the list\n",
    "tree_ID = [int(name) for name in folder_names if name.isdigit()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Tree ID is the key and the image names are the values.\n",
    "idp_img_names = {}\n",
    "for i in range(len(tree_ID)):\n",
    "    idp_img_names[tree_ID[i]] = os.listdir(folder_path + \"/\" + folder_names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to folders containing IDP outputs from reverse projection\n",
    "idp_img_path = {}\n",
    "for i in range(len(tree_ID)):\n",
    "    idp_img_path[tree_ID[i]] = [folder_path + \"/\" + folder_names[i] + \"/\" + idp_img_names[tree_ID[i]][j] for j in range(len(idp_img_names[tree_ID[i]]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate sharpness and contrast for each idp image. \n",
    "def sharpness_contrast(img_path):\n",
    "    # read image\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    # Sharpness is the Laplacian of the image gradients.\n",
    "    sharpness = cv2.Laplacian(img, cv2.CV_64F).var()\n",
    "    # Contrast is the standard deviation of the pixel values in greyscale (RMS contrast).\n",
    "    contrast = np.std(img)\n",
    "    return sharpness, contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the image names to match the raw UAV image names. \n",
    "uav_img_names = {}\n",
    "\n",
    "# Remove \"{treeID}_\" from the start of every image name. \n",
    "for key in idp_img_names.keys():\n",
    "    uav_img_names[key] = [name.split(\"_\", 1)[1] for name in idp_img_names[key]]\n",
    "\n",
    "# Remove rest of image name after \"_D\"\n",
    "for key in uav_img_names.keys():\n",
    "    uav_img_names[key] = [name.split(\"_at\", 1)[0] for name in uav_img_names[key]]\n",
    "\n",
    "# Add \".JPG\" to the end of each image name\n",
    "for key in uav_img_names.keys():\n",
    "    uav_img_names[key] = [name + \".JPG\" for name in uav_img_names[key]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store image names as full path. Image directory is raw_img_folder_path\n",
    "uav_img_path = {}\n",
    "for key in uav_img_names.keys():\n",
    "    uav_img_path[key] = [raw_img_folder_path + \"/\" + name for name in uav_img_names[key]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate gimbal pitch using exiftool. \n",
    "# Gimbal pitch is the angle of the camera from the horizontal plane.\n",
    "def gimbal_pitch(img_path):\n",
    "    with exiftool.ExifToolHelper() as et:\n",
    "        for d in et.get_tags(img_path, tags=[\"GimbalPitchDegree\"]):\n",
    "            return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate sharpness and contrast for all cropped images (the outputs from easyIDP backward projection).\n",
    "sharpness_contrast_cropped = {}\n",
    "for key in idp_img_path.keys():\n",
    "    sharpness_contrast_cropped[key] = [sharpness_contrast(img) for img in idp_img_path[key]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate gimbal pitch for all UAV images.\n",
    "gimbal_pitch_uav = {}\n",
    "for key in uav_img_path.keys():\n",
    "        gimbal_pitch_uav[key] = [gimbal_pitch(img) for img in uav_img_path[key]]\n",
    "        gimbal_pitch_uav[key] = [list(d.values())[1] for d in gimbal_pitch_uav[key]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prioritize gimbal pitch unless sharpness OR contrast highest value is more than 15% larger than \n",
    "# gimbal pitch == 90 (rounded) sharpness or contrast. If no gimbal pitch values are equal to 90 (rounded),\n",
    "# or contrast and sharpness are more than 15% larger than gimbal pitch == 90 (rounded), then the image \n",
    "# with the highest sharpness is selected. If sharpness values are within 15% of each other, then the \n",
    "# image with the highest contrast is selected.\n",
    "\n",
    "def best_img(uav_img_path, sharpness_contrast_cropped, gimbal_pitch_uav):\n",
    "    # store image paths, sharpnes, contrast, and gimbal pitch of every image containing treeID\n",
    "    img_data = []\n",
    "    for i in range(len(uav_img_path)):\n",
    "        img_data.append([uav_img_path[i], sharpness_contrast_cropped[i][0], sharpness_contrast_cropped[i][1], gimbal_pitch_uav[i]])\n",
    "    # convert img_data to a pandas dataframe\n",
    "    df = pd.DataFrame(img_data, columns=[\"img_path\", \"sharpness\", \"contrast\", \"gimbal_pitch\"])\n",
    "    \n",
    "    # Find the images with gimbal pitch == abs(90) when rounded to the nearest whole number\n",
    "    gimbal_pitch_90 = df.loc[df[\"gimbal_pitch\"].abs().round() == 90]\n",
    "\n",
    "    # if multiple images have gimbal pitch == abs(90), or if largest sharpness | contrast for tree \n",
    "    # is more than 15% larger than the largest sharpness/contrast value for gimbal pitch == 90,\n",
    "    # best image is the image with the highest sharpness. \n",
    "    if len(gimbal_pitch_90) == 0 or (df[\"sharpness\"].max() - gimbal_pitch_90[\"sharpness\"].max() > 0.15 * df[\"sharpness\"].max()) or (df[\"contrast\"].max() - gimbal_pitch_90[\"contrast\"].max() > 0.15 * df[\"contrast\"].max()):\n",
    "        best_image = df.loc[df[\"sharpness\"] == df[\"sharpness\"].max(), \"img_path\"].values[0]\n",
    "\n",
    "        # is the next highest sharpness value within 15% of the highest sharpness value?\n",
    "        if df[\"sharpness\"].max() - df[\"sharpness\"].nlargest(2).iloc[-1] <= 0.15 * df[\"sharpness\"].max():\n",
    "            \n",
    "            # if so, best image is the image with the highest contrast\n",
    "            max_contrast = df[\"contrast\"].max()\n",
    "            best_image = df.loc[df[\"contrast\"] == max_contrast, \"img_path\"].values[0]\n",
    "\n",
    "    # if not, best image is the image with the highest gimbal pitch == abs(90)\n",
    "    else:\n",
    "        best_image = gimbal_pitch_90.loc[gimbal_pitch_90[\"gimbal_pitch\"] == gimbal_pitch_90[\"gimbal_pitch\"], \"img_path\"].values[0]\n",
    "\n",
    "    return best_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each tree ID, find the best UAV image\n",
    "best_images = {}\n",
    "for key in uav_img_path.keys():\n",
    "    best_images[key] = best_img(uav_img_path[key], sharpness_contrast_cropped[key], gimbal_pitch_uav[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pixel coordinates dictionary of best 5 images for each tree canopy from pkl file\n",
    "with open(dir + \"ROI_pixelCoords_best5.pkl\", \"rb\") as f:\n",
    "    pixelCoords = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add .JPG to end of image keys in pixel coords dictionary for each tree ID\n",
    "for key in pixelCoords.keys():\n",
    "    pixelCoords[key] = {k + \".JPG\": v for k, v in pixelCoords[key].items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_images dict contains the file path of the best image for each tree ID. Use the file path to get the image name.\n",
    "best_image_names = {}\n",
    "for key in best_images.keys():\n",
    "    best_image_names[key] = best_images[key].split(\"/\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use best image name to get corresponding pixel coordinates from pixelCoords dictionary\n",
    "best_image_pixelCoords = {}\n",
    "for key in best_image_names.keys():\n",
    "    best_image_pixelCoords[key] = pixelCoords[f'{key}'][best_image_names[key]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for reshaping polygons \n",
    "def get_polygon(polygons):\n",
    "    polygons = np.array(polygons)\n",
    "    polygons = polygons.astype('float').reshape(-1, 2)\n",
    "    if polygons.shape[0] == 1 : return polygons\n",
    "    return np.squeeze(polygons)\n",
    "\n",
    "# function for plotting image\n",
    "def img_show(image, ax = None, figsize = (6, 9)):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize = figsize)\n",
    "    ax.imshow(image)\n",
    "    # ax.xaxis.tick_top()\n",
    "    ax.axis('off')\n",
    "    return ax\n",
    "\n",
    "# Function for plotting mask\n",
    "def plot_mask(ax, polygons):\n",
    "    ax.plot(polygons[:, 0], polygons[:, 1], c = 'y', linewidth = 0.7, alpha = 0.8)\n",
    "    return ax\n",
    "\n",
    "# function for plotting image with mask\n",
    "def plot_img_mask(image, polygon):\n",
    "    ax = img_show(image)\n",
    "    polygon = get_polygon(polygon)\n",
    "    plot_mask(ax, polygon)\n",
    "    return ax\n",
    "\n",
    "# modify get_bbox function to buffer the bounding box\n",
    "def get_buffered_bbox(image, polygon, buffer):\n",
    "    xmin = np.min(polygon[:, 0])\n",
    "    xmax = np.max(polygon[:, 0])\n",
    "    ymin = np.min(polygon[:, 1])\n",
    "    ymax = np.max(polygon[:, 1])\n",
    "    bbox = [max(0, xmin - buffer), max(0, ymin - buffer), min(xmax + buffer, image.size[0]), min(ymax + buffer, image.size[1])]\n",
    "    return bbox\n",
    "\n",
    "# Function to crop image using buffered bounding box\n",
    "def crop_image_bbox(image, bbox, buffer):\n",
    "    xmin, ymin, xmax, ymax = bbox\n",
    "    xmin = max(0, xmin - buffer)\n",
    "    ymin = max(0, ymin - buffer)\n",
    "    xmax = min(image.size[0], xmax + buffer)\n",
    "    ymax = min(image.size[1], ymax + buffer)\n",
    "    return image.crop((xmin, ymin, xmax, ymax))\n",
    "\n",
    "# modify polygon coords to reflect crop\n",
    "def crop_polygon(image, polygon, bbox, buffer):\n",
    "    xmin, ymin, xmax, ymax = bbox\n",
    "    xmin = max(0, xmin - buffer)\n",
    "    ymin = max(0, ymin - buffer)\n",
    "    xmax = min(image.size[0], xmax + buffer)\n",
    "    ymax = min(image.size[1], ymax + buffer)\n",
    "    polygon[:, 0] = np.clip(polygon[:, 0], xmin, xmax)\n",
    "    polygon[:, 1] = np.clip(polygon[:, 1], ymin, ymax)\n",
    "    polygon[:, 0] -= xmin\n",
    "    polygon[:, 1] -= ymin\n",
    "    return polygon\n",
    "\n",
    "# function to crop image using buffered bounding box\n",
    "def crop_image(image, polygon, buffer):\n",
    "    bbox = get_buffered_bbox(image, polygon, buffer)\n",
    "    cropped_image = crop_image_bbox(image, bbox, buffer)\n",
    "    cropped_polygon = crop_polygon(image, polygon, bbox, buffer)\n",
    "    return cropped_image, cropped_polygon\n",
    "\n",
    "\n",
    "# Calculate bbox in COCO format of cropped polygon\n",
    "def get_coco_bbox(polygon):\n",
    "    xmin = np.min(polygon[:, 0])\n",
    "    xmax = np.max(polygon[:, 0])\n",
    "    ymin = np.min(polygon[:, 1])\n",
    "    ymax = np.max(polygon[:, 1])\n",
    "    bbox = [xmin, ymin, xmax - xmin, ymax - ymin]\n",
    "    return bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create folder in dir for storing raw UAV images in .PNG format. \n",
    "png_folder = dir + \"best_image_PNGs/\"\n",
    "if not os.path.exists(png_folder):\n",
    "    os.makedirs(png_folder)\n",
    "\n",
    "# create folder in dir for storing cropped images in .PNG format.\n",
    "cropped_png_folder = dir + \"Roboflow/images/\"\n",
    "if not os.path.exists(cropped_png_folder):\n",
    "    os.makedirs(cropped_png_folder)\n",
    "\n",
    "# create folder in dir for storing annotation JSON\n",
    "annotation_folder = dir + \"Roboflow/annotations/\"\n",
    "if not os.path.exists(annotation_folder):\n",
    "    os.makedirs(annotation_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each tree ID, crop the best image and save the cropped image with cropped polygon mask\n",
    "cropped_polygons = {}\n",
    "for key in best_image_pixelCoords.keys():\n",
    "    image = PIL.Image.open(best_images[key])\n",
    "    # copy the best image as png with transparent background and same dpi as original image in temp folder\n",
    "    image.save(png_folder + str(key) + \".png\", format = \"PNG\", dpi = (image.info[\"dpi\"][0], image.info[\"dpi\"][1]))\n",
    "    # load best image png\n",
    "    image = PIL.Image.open(png_folder + str(key) + \".png\")\n",
    "    polygon = best_image_pixelCoords[key]\n",
    "    buffer = int(200)\n",
    "    cropped_image, cropped_polygon = crop_image(image, polygon, buffer)\n",
    "    cropped_polygons[key] = cropped_polygon\n",
    "    # save cropped image as png with transparent background and same dpi as original image in cropped_png_folder\n",
    "    cropped_image.save(cropped_png_folder + str(key) + \".png\", format = \"PNG\", dpi = (image.info[\"dpi\"][0], image.info[\"dpi\"][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best image and corresponding cropped image polygon coordinates to a JSON file in COCO format. \n",
    "# COCO JSON file includes the following fields: \n",
    "\n",
    "# “info”: This field contains metadata about the dataset, such as the version, description, and contributor information\n",
    "\n",
    "# “licenses”: This field contains information about the licenses associated with the images and videos in the dataset\n",
    "\n",
    "# “images”: This field contains a list of dictionaries, each representing an image in the dataset. Each dictionary includes the following fields:\n",
    "#     “id”: The unique identifier for the image (i.e., key/treeID)\n",
    "#     “width”: The width of the image in pixels\n",
    "#     “height”: The height of the image in pixels\n",
    "#     “file_name”: The file name of the image\n",
    "#     “license”: The license associated with the image\n",
    "#     “date_captured”: The date the image was captured (optional)\n",
    "\n",
    "# “annotations”: This field contains a list of dictionaries, each representing an annotation for an image in the dataset. Each dictionary includes the following fields:\n",
    "#     “id”: The unique identifier for the annotation (i.e., key/treeID)\n",
    "#     “image_id”: The identifier for the image to which the annotation belongs\n",
    "#     “category_id”: The identifier for the category (i.e., class) to which the annotation belongs\n",
    "#     “bbox”: The bounding box for the annotation (i.e., bounding box of the canopy polygon in x,y,w,h format)\n",
    "#     “area”: The area of the bbox in square pixels (w * h)\n",
    "#     “segmentation”: The segmentation mask for the annotation (i.e., canopy polygon)\n",
    "#     “iscrowd”: A binary flag indicating whether the annotation represents a single object or a group of objects)\n",
    "#     “attributes”: Additional attributes associated with the annotation (optional)\n",
    "\n",
    "###-------------------------------------------------------------------------------------------------------------------------------------------------------------------------###\n",
    "\n",
    "# create the COCO JSON file\n",
    "coco_data = {}\n",
    "coco_data[\"info\"] = {\n",
    "    \"description\": \"Route 9 Orchard 4\",\n",
    "    \"version\": \"1.0\",\n",
    "    \"contributor\": \"Zack Loken\",\n",
    "    \"date_created\": \"2024-07-04\"\n",
    "}\n",
    "\n",
    "coco_data[\"licenses\"] = [\n",
    "    {\n",
    "        \"url\": \"https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en\",\n",
    "        \"id\": 1,\n",
    "        \"name\": \"Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License\"\n",
    "    }\n",
    "]\n",
    "\n",
    "coco_data[\"images\"] = []\n",
    "coco_data[\"annotations\"] = []\n",
    "\n",
    "# add cropped best_image data from cropped_png_folder + str(key) + \".png\") to coco_data[\"images\"]\n",
    "for key in best_images.keys():\n",
    "    image = PIL.Image.open(cropped_png_folder + str(key) + \".png\")\n",
    "    image_data = {\n",
    "        \"id\": key,\n",
    "        \"width\": image.size[0],\n",
    "        \"height\": image.size[1],\n",
    "        \"file_name\": str(key) + \".png\",\n",
    "        \"license\": 1,\n",
    "        \"date_captured\": \"08-23-2023\"\n",
    "    }\n",
    "    coco_data[\"images\"].append(image_data)\n",
    "\n",
    "# add cropped_polygon data from cropped_polygons[key] to coco_data[\"annotations\"]\n",
    "for key in cropped_polygons.keys():\n",
    "    cropped_polygon = cropped_polygons[key]\n",
    "    # Calculate bbox in COCO format of cropped polygon\n",
    "    bbox = get_coco_bbox(cropped_polygon)\n",
    "    area = bbox[2] * bbox[3]\n",
    "    annotation_data = {\n",
    "        # id is original uav image name\n",
    "        \"id\": uav_img_names[key][0],\n",
    "        \"image_id\": key,\n",
    "        \"category_id\": \"Canopy\",\n",
    "        \"bbox\": bbox,\n",
    "        \"area\": area,\n",
    "        \"segmentation\": [cropped_polygon.flatten().tolist()],\n",
    "        \"iscrowd\": False,\n",
    "        \"attributes\": {}\n",
    "    }\n",
    "    coco_data[\"annotations\"].append(annotation_data)\n",
    "\n",
    "# save coco_data to a JSON file\n",
    "with open(annotation_folder + \"canopyMasks.coco.json\", \"w\") as f:\n",
    "    json.dump(coco_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Upload best cropped images and corresponding canopy polygons to Roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the images and annotations to Roboflow\n",
    "import glob\n",
    "from roboflow import Roboflow\n",
    "\n",
    "# API Key for project workspace:\n",
    "api_key = \"5dM5PdVffGR3ONX8CeRu\"\n",
    "\n",
    "# Initialize Roboflow client\n",
    "rf = Roboflow(api_key=api_key)\n",
    "\n",
    "# Retrieve your current workspace and project name\n",
    "print(rf.workspace())\n",
    "\n",
    "# annotation file path\n",
    "annotation_path = annotation_folder + \"canopyMasks.coco.json\"\n",
    "\n",
    "project = rf.workspace('chestnut-detection').project('route-9-orchard-3')\n",
    "\n",
    "# # Upload images and annotations to Roboflow\n",
    "# image_glob = glob.glob(cropped_png_folder + '/*' + \".png\")\n",
    "# for image_path in image_glob:\n",
    "#     print(project.single_upload(image_path = image_path, \n",
    "#                          annotation_path = annotation_path,\n",
    "#                          num_retry_uploads = 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve images and annotations for easyIDP forward projection to CRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Failed to download image or annotation for 0usbXKCwSe8Gk6DfKbkM: 'url'\n",
      "Failed to download image or annotation for 4q1Ub5hNMvct2WqwSE8X: 'url'\n",
      "Failed to download image or annotation for zewEj8RdRE8j7DnIuR3B: 'url'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 41\u001b[0m\n\u001b[0;32m     38\u001b[0m image_id \u001b[38;5;241m=\u001b[39m record[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m# Use the search method to get the image details\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m     image_details \u001b[38;5;241m=\u001b[39m \u001b[43mproject\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m image_details:\n\u001b[0;32m     43\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\zack\\anaconda3\\envs\\easyidp\\lib\\site-packages\\roboflow\\core\\project.py:690\u001b[0m, in \u001b[0;36mProject.search\u001b[1;34m(self, like_image, prompt, offset, limit, tag, class_name, in_dataset, batch, batch_id, fields)\u001b[0m\n\u001b[0;32m    686\u001b[0m     payload[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_id\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m batch_id\n\u001b[0;32m    688\u001b[0m payload[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfields\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m fields\n\u001b[1;32m--> 690\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    691\u001b[0m \u001b[43m    \u001b[49m\u001b[43mAPI_URL\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__workspace\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__project_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/search?api_key=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__api_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    692\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpayload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    693\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    695\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\u001b[38;5;241m.\u001b[39mjson()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\zack\\anaconda3\\envs\\easyidp\\lib\\site-packages\\requests\\api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[1;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \n\u001b[0;32m    106\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, data\u001b[38;5;241m=\u001b[39mdata, json\u001b[38;5;241m=\u001b[39mjson, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\zack\\anaconda3\\envs\\easyidp\\lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\zack\\anaconda3\\envs\\easyidp\\lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\zack\\anaconda3\\envs\\easyidp\\lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\zack\\anaconda3\\envs\\easyidp\\lib\\site-packages\\requests\\adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    483\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[1;32mc:\\Users\\zack\\anaconda3\\envs\\easyidp\\lib\\site-packages\\urllib3\\connectionpool.py:790\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    787\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    789\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 790\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    791\u001b[0m     conn,\n\u001b[0;32m    792\u001b[0m     method,\n\u001b[0;32m    793\u001b[0m     url,\n\u001b[0;32m    794\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    795\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    796\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    797\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    798\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[0;32m    799\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[0;32m    800\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    801\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    802\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    803\u001b[0m )\n\u001b[0;32m    805\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[0;32m    806\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\zack\\anaconda3\\envs\\easyidp\\lib\\site-packages\\urllib3\\connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    534\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32mc:\\Users\\zack\\anaconda3\\envs\\easyidp\\lib\\site-packages\\urllib3\\connection.py:461\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    458\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[0;32m    460\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[1;32m--> 461\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    464\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[1;32mc:\\Users\\zack\\anaconda3\\envs\\easyidp\\lib\\http\\client.py:1377\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1375\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1376\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1377\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1378\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1379\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\zack\\anaconda3\\envs\\easyidp\\lib\\http\\client.py:320\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    322\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\zack\\anaconda3\\envs\\easyidp\\lib\\http\\client.py:281\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 281\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    283\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\zack\\anaconda3\\envs\\easyidp\\lib\\socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    703\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 704\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    706\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\zack\\anaconda3\\envs\\easyidp\\lib\\ssl.py:1275\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1271\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1272\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1273\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1274\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1275\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1276\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\Users\\zack\\anaconda3\\envs\\easyidp\\lib\\ssl.py:1133\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1133\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1134\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1135\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from roboflow import Roboflow\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "\n",
    "# API Key for project workspace:\n",
    "api_key = \"5dM5PdVffGR3ONX8CeRu\"\n",
    "\n",
    "# Initialize Roboflow client\n",
    "rf = Roboflow(api_key=api_key)\n",
    "\n",
    "# Retrieve your current workspace and project names\n",
    "workspace = rf.workspace('chestnut-detection')\n",
    "project = workspace.project('route-9-orchard-3')\n",
    "\n",
    "# Output directory for images and annotations\n",
    "out_dir = \"S:/Zack/Imagery/Chestnut/roboflow/route9_orchard3\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "# List all images in the project using search_all\n",
    "records = []\n",
    "for page in project.search_all(\n",
    "    prompt=\"\",\n",
    "    like_image=\"\",\n",
    "    offset=0,\n",
    "    limit=100,\n",
    "    tag=\"\",\n",
    "    class_name=\"\",\n",
    "    in_dataset=False,  # Set to False to include images not in a dataset\n",
    "    batch=False,\n",
    "    batch_id=\"\",\n",
    "    fields=[\"id\", \"created\", \"name\", \"labels\"],\n",
    "):\n",
    "    records.extend(page)\n",
    "\n",
    "# Download images and annotations\n",
    "for record in records:\n",
    "    image_id = record[\"id\"]\n",
    "    try:\n",
    "        # Use the search method to get the image details\n",
    "        image_details = project.search(image_id)\n",
    "        if not image_details:\n",
    "            raise ValueError(f\"Image {image_id} not found.\")\n",
    "        \n",
    "        image = image_details[0]  # Assuming the first result is the correct image\n",
    "        \n",
    "        # Download the image using the URL\n",
    "        image_url = image['url']\n",
    "        image_response = requests.get(image_url)\n",
    "        image_path = os.path.join(out_dir, f\"{image['name']}.jpg\")\n",
    "        with open(image_path, 'wb') as f:\n",
    "            f.write(image_response.content)\n",
    "        \n",
    "        # Get the annotation file\n",
    "        annotation = image['labels']\n",
    "        \n",
    "        # Save the annotation file\n",
    "        annotation_path = os.path.join(out_dir, f\"{image['name']}.json\")\n",
    "        with open(annotation_path, \"w\") as f:\n",
    "            json.dump(annotation, f)\n",
    "        \n",
    "        print(f\"Downloaded image and annotation for {image_id}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download image or annotation for {image_id}: {e}\")\n",
    "\n",
    "print(\"Download complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_Project__api_key', '_Project__project_name', '_Project__workspace', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_annotation_params', 'annotation', 'check_valid_image', 'classes', 'colors', 'created', 'generate_version', 'get_version_information', 'id', 'images', 'list_versions', 'model_format', 'multilabel', 'name', 'public', 'save_annotation', 'search', 'search_all', 'single_upload', 'splits', 'train', 'type', 'unannotated', 'updated', 'upload', 'upload_image', 'version', 'versions']\n"
     ]
    }
   ],
   "source": [
    "print(dir(project))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "easyidp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
