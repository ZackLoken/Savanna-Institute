{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>Chestnut Bur Detection and Segmentation using MaskRCNN in PyTorch</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, Subset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms as _transforms, tv_tensors\n",
    "import torchvision.transforms.v2 as T\n",
    "from torchvision.transforms import functional as F\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import gc\n",
    "import os\n",
    "from PIL import Image, ImageDraw, ImageOps\n",
    "\n",
    "from segmentation_pytorch import engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <center> Load the image and annotation data </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load annotations from json file here: \"C:\\Users\\exx\\Downloads\\Route 9 Orchard 3.v1-test_dataset.coco-segmentation\\train\\_annotations.coco.json\"\n",
    "annos = json.load(open(\"C:/Users/exx/Deep Learning/Chestnut_Bur_Instance_Segmentation/route9_orchard3/data/_annotations.coco.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the annos dict to a df\n",
    "annos_df = pd.DataFrame(annos[\"annotations\"])\n",
    "df = pd.DataFrame()\n",
    "df[\"tree_id\"] = annos_df[\"image_id\"].apply(lambda x: annos[\"images\"][x][\"file_name\"].split(\"_\")[0])\n",
    "df[\"file_name\"] = annos_df[\"image_id\"].apply(lambda x: annos[\"images\"][x][\"file_name\"])\n",
    "df[\"file_name\"] = df[\"file_name\"].apply(lambda x: x.split(\"_\")[0] + \".png\")\n",
    "categories = [cat[\"name\"] for cat in annos[\"categories\"]]\n",
    "df[\"category_name\"] = annos_df[\"category_id\"].apply(lambda x: categories[x])\n",
    "df[\"bbox\"] = annos_df[\"bbox\"].apply(lambda x: torch.tensor(x))\n",
    "df[\"area\"] = annos_df[\"area\"].apply(lambda x: torch.tensor(x))\n",
    "df[\"segmentation\"] = annos_df[\"segmentation\"].apply(lambda x: torch.tensor(x))\n",
    "df[\"iscrowd\"] = annos_df[\"iscrowd\"]\n",
    "\n",
    "# Filter df to remove treeIds not reviewed. \n",
    "reviewed_trees = [\n",
    "    14, 44, 51, 60, 79, 91, 92, 117, 118, 146, 152, 171, \n",
    "    172, 210, 272, 276, 280, 286, 304, 309, 320, 329, \n",
    "    366, 369, 371, 392, 394, 405\n",
    "]\n",
    "\n",
    "df = df[df[\"tree_id\"].isin([str(tree_id) for tree_id in reviewed_trees])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"C:/Users/exx/Deep Learning/Chestnut_Bur_Instance_Segmentation/route9_orchard3/data/images\"\n",
    "image_names = df[\"file_name\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot each image with its canopy polygon mask and chestnut polygon masks\n",
    "\n",
    "# os.makedirs(\"C:/Users/exx/Deep Learning/Chestnut_Bur_Instance_Segmentation/route9_orchard3/annotated_images\", exist_ok=True)\n",
    "\n",
    "# for i, tree_id in enumerate(df[\"tree_id\"].unique()):\n",
    "#     image_file = Path(image_dir) / df[df[\"tree_id\"] == tree_id][\"file_name\"].values[0]\n",
    "#     image = Image.open(image_file)\n",
    "#     # get image width and height\n",
    "#     width, height = image.size\n",
    "\n",
    "#     # print(f\"tree {tree_id} has a width of {width} and height of {height} pixels\")\n",
    "\n",
    "#     canopy_poly = df[(df[\"tree_id\"] == tree_id) & (df[\"category_name\"] == \"Canopy\")][\"segmentation\"].values\n",
    "#     bur_poly = df[(df[\"tree_id\"] == tree_id) & (df[\"category_name\"] == \"Chestnut-burr\")][\"segmentation\"].values\n",
    "\n",
    "#     canopy_poly = [np.array(poly[0]).reshape(-1, 2).astype(np.int32) for poly in canopy_poly]\n",
    "#     bur_poly = [np.array(poly[0]).reshape(-1, 2).astype(np.int32) for poly in bur_poly]\n",
    "\n",
    "#     # Create a drawing context\n",
    "#     draw = ImageDraw.Draw(image)\n",
    "    \n",
    "#     for poly in canopy_poly:\n",
    "#         draw.polygon([tuple(point) for point in poly], outline=\"purple\", width=2)\n",
    "#     for poly in bur_poly:\n",
    "#         draw.polygon([tuple(point) for point in poly], outline=\"red\")\n",
    "\n",
    "#     # Save the image\n",
    "#     image.save(f\"C:/Users/exx/Deep Learning/Chestnut_Bur_Instance_Segmentation/route9_orchard3/annotated_images/{tree_id}_annotated.png\", format='PNG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <center> Pre-process and transform image and annotation data </center>\n",
    "\n",
    "##### Adapted from: https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html#an-instance-segmentation-model-for-pennfudan-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_fill(mask, polys, color):\n",
    "    from cv2 import fillPoly\n",
    "    for poly in polys:\n",
    "        fillPoly(mask, [poly], color)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom dataset loader (PyTorch) for loading images and annotation data\n",
    "class ChestnutBurSegmentation(Dataset):\n",
    "    \"\"\"Custom Dataset for Chestnut Bur Segmentation in UAV Images\"\"\"\n",
    "\n",
    "    def __init__(self, image_dir, df, transform = None):\n",
    "        self.image_dir = image_dir\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        self.unique_tree_ids = self.df[\"tree_id\"].unique()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        tree_id = self.unique_tree_ids[idx]\n",
    "\n",
    "        row = self.df[self.df[\"tree_id\"] == tree_id].iloc[0]\n",
    "\n",
    "        image_file = Path(self.image_dir) / row[\"file_name\"]\n",
    "\n",
    "        image = tv_tensors.Image(Image.open(image_file))\n",
    "\n",
    "        height, width = image.shape[-2:]\n",
    "\n",
    "        canopy_poly = self.df[(self.df[\"tree_id\"] == tree_id) & (self.df[\"category_name\"] == \"Canopy\")][\"segmentation\"].values\n",
    "        bur_poly = self.df[(self.df[\"tree_id\"] == tree_id) & (self.df[\"category_name\"] == \"Chestnut-burr\")][\"segmentation\"].values\n",
    "\n",
    "\n",
    "        canopy_poly = [np.array(poly[0]).reshape(-1, 2).astype(np.int32) for poly in canopy_poly]\n",
    "        bur_poly = [np.array(poly[0]).reshape(-1, 2).astype(np.int32) for poly in bur_poly]\n",
    "\n",
    "\n",
    "        # get canopy_bbox coords [xmin, ymin, xmax, ymax]\n",
    "        xmin, ymin, xmax, ymax = min([poly[:, 0].min() for poly in canopy_poly]), min([poly[:, 1].min() for poly in canopy_poly]), max([poly[:, 0].max() for poly in canopy_poly]), max([poly[:, 1].max() for poly in canopy_poly])\n",
    "\n",
    "\n",
    "        canopy_mask = np.zeros((height, width), dtype=np.uint8)\n",
    "        canopy_mask = mask_fill(canopy_mask, canopy_poly, 1)\n",
    "\n",
    "        bur_masks = []\n",
    "        # One mask per bur. Store each bur mask in a list to stack later. \n",
    "        for poly in bur_poly:\n",
    "            bur_mask = np.zeros((height, width), dtype=np.uint8)\n",
    "            bur_mask = mask_fill(bur_mask, [poly], 2)\n",
    "            bur_masks.append(bur_mask)\n",
    "\n",
    "        background_mask = np.zeros((height, width, 1), dtype=np.uint8)\n",
    "        bur_masks_stacked = np.stack(bur_masks, axis=-1)\n",
    "        mask_image = np.concatenate([background_mask, bur_masks_stacked], axis=-1).transpose(2, 0, 1)\n",
    "        labels = self.df[(self.df[\"tree_id\"] == tree_id) & (self.df[\"category_name\"] == \"Chestnut-burr\")][\"category_name\"].values\n",
    "        labels = [categories.index(label) for label in labels]\n",
    "        bboxes = self.df[(self.df[\"tree_id\"] == tree_id) & (self.df[\"category_name\"] == \"Chestnut-burr\")][\"bbox\"].values\n",
    "        bboxes = [torch.tensor([bbox[0], bbox[1], bbox[0] + bbox[2], bbox[1] + bbox[3]], dtype = torch.float32) for bbox in bboxes] # convert to xyxy format\n",
    "        bboxes = torch.stack([bbox for bbox in bboxes], dim=0) # (n_objects, 4)\n",
    "        area = self.df[(self.df[\"tree_id\"] == tree_id) & (self.df[\"category_name\"] == \"Chestnut-burr\")][\"area\"].values\n",
    "        iscrowd = self.df[(self.df[\"tree_id\"] == tree_id) & (self.df[\"category_name\"] == \"Chestnut-burr\")][\"iscrowd\"].values\n",
    "\n",
    "        # fill image background (outside of tree canopy)\n",
    "        image = image * np.array(canopy_mask).astype(np.uint8)\n",
    "\n",
    "        target = {}\n",
    "        target[\"boxes\"] = tv_tensors.BoundingBoxes(bboxes, format=tv_tensors.BoundingBoxFormat.XYXY, canvas_size=(height, width)) \n",
    "        target[\"labels\"] = torch.as_tensor(labels, dtype = torch.int64) # (n_objects)\n",
    "        target[\"image_id\"] = int(tree_id)\n",
    "        target[\"area\"] = torch.stack([a.clone().detach().float() for a in area], dim=0) # (n_objects)\n",
    "        target[\"iscrowd\"] = torch.stack([torch.tensor(ic, dtype = torch.int64) for ic in iscrowd], dim=0) # (n_objects)\n",
    "\n",
    "        image = T.Compose([T.ToDtype(torch.float32, scale=True),\n",
    "                           T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])(image)\n",
    "        \n",
    "        image_and_mask = torch.cat((image, torch.tensor(mask_image, dtype=torch.float32)), dim=0)\n",
    "\n",
    "        # crop image_and_mask to xmin, ymin, xmax, ymax\n",
    "        image_and_mask = image_and_mask[:, (int(ymin)-50):(int(ymax)+50), (int(xmin)-50):(int(xmax)+50)] # pad by 50 in each direction\n",
    "            \n",
    "        if self.transform is not None:\n",
    "            image_and_mask, target = self.transform(image_and_mask, target)\n",
    "        \n",
    "        image = image_and_mask[:image.shape[0], :, :] # slice out the transformed image\n",
    "        mask_image = image_and_mask[image.shape[0]:, :].clone().detach().to(torch.uint8) # slice out the transformed mask\n",
    "\n",
    "        target[\"masks\"] = mask_image\n",
    "\n",
    "        return image, target\n",
    "        \n",
    "    def collate_fn(batch):\n",
    "        return tuple(zip(*batch))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.unique_tree_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define transforms for the dataset\n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    \n",
    "    if train:\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    transforms.append(T.ClampBoundingBoxes()) # for segmentations too\n",
    "    transforms.append(T.SanitizeBoundingBoxes()) ## for segmentations too\n",
    "\n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ds = ChestnutBurSegmentation(image_dir, df, get_transform(train = True))\n",
    "sample_dl = DataLoader(sample_ds, batch_size = 4, shuffle = True, collate_fn = ChestnutBurSegmentation.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, targets = next(iter(sample_dl))\n",
    "images = [img for img in images]\n",
    "targets = [{k: v for k, v in target.items()} for target in targets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <center> Plot sample transformed images, targets, and masks </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "tree_ids = [target[\"image_id\"] for target in targets]\n",
    "\n",
    "image = images[3].permute(1, 2, 0)\n",
    "mask = targets[3][\"masks\"].permute(1, 2, 0)\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.title(\"transformed image\")\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(mask.sum(axis=2), cmap=\"gray\")\n",
    "plt.title(\"chestnut bur masks\")\n",
    "plt.show()\n",
    "\n",
    "# plot mask on image\n",
    "plt.imshow(image)\n",
    "plt.imshow(mask.sum(axis=2), cmap='gray', alpha=0.75)\n",
    "plt.title(\"training sample\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save each transformed image with its canopy mask and chestnut polygon masks to a folder. Name image treeID.png\n",
    "\n",
    "# os.makedirs(\"C:/Users/exx/Deep Learning/Chestnut_Bur_Instance_Segmentation/route9_orchard3/transformed_images\", exist_ok=True)\n",
    "\n",
    "# for i, (image, target) in enumerate(zip(images, targets)):\n",
    "\n",
    "#     tree_id = target[\"image_id\"]\n",
    "#     image = image.permute(1, 2, 0)\n",
    "#     mask = target[\"masks\"].permute(1, 2, 0)\n",
    "\n",
    "#     #plot mask on image and save to .png file\n",
    "#     plt.imshow(image)\n",
    "#     plt.imshow(mask.sum(axis=2), cmap='gray', alpha=0.75)\n",
    "#     plt.savefig(f\"C:/Users/exx/Deep Learning/Chestnut_Bur_Instance_Segmentation/route9_orchard3/transformed_images/{tree_id}_transformed.png\")\n",
    "#     plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <center> Construct MaskRCNN Model </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_instance_segmentation_model(num_classes):\n",
    "    # Load a Mask R-CNN instance segmentation model pre-trained on COCO\n",
    "    model = torchvision.models.detection.maskrcnn_resnet50_fpn_v2(\n",
    "        weights=torchvision.models.detection.MaskRCNN_ResNet50_FPN_V2_Weights.DEFAULT,\n",
    "        weights_backbone=torchvision.models.ResNet50_Weights.DEFAULT\n",
    "    )\n",
    "\n",
    "    # Get the number of input features for the classifier\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "\n",
    "    # Replace the pre-trained head with a new one to reflect the number of classes\n",
    "    model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "    # Get the number of input features for the mask classifier\n",
    "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "    hidden_layer = 256\n",
    "\n",
    "    # Replace the mask predictor with a new one\n",
    "    model.roi_heads.mask_predictor = torchvision.models.detection.mask_rcnn.MaskRCNNPredictor(\n",
    "        in_features_mask,\n",
    "        hidden_layer,\n",
    "        num_classes\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_instance_segmentation_model(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <center> Tune model hyperparameters using bayesian optimization algo and hyperband scheduler </center>\n",
    "\n",
    "##### adapted from: https://docs.ray.io/en/latest/tune/examples/bohb_example.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayesian Optimization HyperBand (BOHB) with HyperBand scheduler\n",
    "# # https://proceedings.mlr.press/v80/falkner18a.html\n",
    "\n",
    "import tempfile\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import ray\n",
    "from ray import train, tune\n",
    "from ray.tune.schedulers.hb_bohb import HyperBandForBOHB\n",
    "from ray.tune.search.bohb import TuneBOHB\n",
    "\n",
    "import ConfigSpace as CS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store indices in random order list for subsetting later\n",
    "indices = torch.randperm(len(sample_ds)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(image_dir = image_dir, df = df): \n",
    "    train_ds = ChestnutBurSegmentation(image_dir, df, get_transform(train = True))\n",
    "    val_ds = ChestnutBurSegmentation(image_dir, df, get_transform(train = False))\n",
    "    return train_ds, val_ds\n",
    "\n",
    "\n",
    "def train_ChestnutBurSegmentation(search_space, indices):\n",
    "    model = get_instance_segmentation_model(num_classes = 2) # background, chestnut bur\n",
    "    \n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            model = nn.DataParallel(model) # train on multiple gpus if available\n",
    "    model.to(device)\n",
    "\n",
    "    # construct an optimizer\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = torch.optim.SGD(params, \n",
    "                                lr = search_space[\"lr\"], \n",
    "                                momentum = search_space[\"momentum\"], \n",
    "                                weight_decay = search_space[\"weight_decay\"])\n",
    "\n",
    "    warmup_factor = 1.0 / 1000\n",
    "    warmup_iters = min(1000, int(len(indices)*0.8) - 1)\n",
    "\n",
    "    # construct a learning rate scheduler\n",
    "    lr_scheduler = torch.optim.lr_scheduler.LinearLR(\n",
    "            optimizer, start_factor=warmup_factor, total_iters=warmup_iters\n",
    "        )\n",
    "    \n",
    "    # load existing checkpoint if available\n",
    "    if train.get_checkpoint():\n",
    "        loaded_checkpoint = train.get_checkpoint()\n",
    "        with loaded_checkpoint.as_directory() as loaded_checkpoint_dir:\n",
    "            model_state, optimizer_state = torch.load(\n",
    "                os.path.join(loaded_checkpoint_dir, \"checkpoint.pt\")\n",
    "            )\n",
    "            model.load_state_dict(model_state)\n",
    "            optimizer.load_state_dict(optimizer_state)\n",
    "    else:\n",
    "        start_epoch = 0\n",
    "\n",
    "    # load data\n",
    "    train_ds, val_ds = load_data()\n",
    "    \n",
    "    train_ds = Subset(train_ds, indices[:-int(len(train_ds)*0.2)]) # first 80% of dataset for training\n",
    "    val_ds = Subset(val_ds, indices[-int(len(train_ds)*0.2):-int(len(train_ds)*0.05)]) # next 15% of dataset for validation\n",
    "\n",
    "    train_dl = DataLoader(train_ds, batch_size = search_space[\"batch_size\"], shuffle = True, collate_fn = ChestnutBurSegmentation.collate_fn, num_workers=0, pin_memory=True)\n",
    "    val_dl = DataLoader(val_ds, batch_size = 1, shuffle = False, collate_fn = ChestnutBurSegmentation.collate_fn, num_workers=0, pin_memory=True)\n",
    "\n",
    "    # put large objects in Ray object store to help memory errors\n",
    "    ray.put(model, train_ds, val_ds, val_dl)\n",
    "\n",
    "    # Main training function\n",
    "    for epoch in range(start_epoch, search_space[\"epochs\"]):\n",
    "        # train for one epoch, printing every 10 iterations\n",
    "        train_logger, val_logger = engine.train_one_epoch(model, optimizer, train_dl, val_dl, device, epoch, print_freq=10, scaler=None)\n",
    "        # update the learning rate\n",
    "        lr_scheduler.step()\n",
    "        # evaluate on the test dataset\n",
    "        train_metrics, val_metrics = engine.evaluate(model, val_dl, device, train_dl)\n",
    "\n",
    "        # save checkpoint\n",
    "         # Here we save a checkpoint. It is automatically registered with Ray Tune\n",
    "        with tempfile.TemporaryDirectory() as temp_checkpoint_dir:\n",
    "            path = os.path.join(temp_checkpoint_dir, \"checkpoint.pt\")\n",
    "            torch.save(\n",
    "                (model.state_dict(), optimizer.state_dict()), path\n",
    "            )\n",
    "            checkpoint = train.Checkpoint.from_directory(temp_checkpoint_dir)\n",
    "            train.report(\n",
    "                {\"train_loss\": train_logger.loss.global_avg, # train loss,\n",
    "                 \"val_loss\": val_logger.loss.global_avg, # val loss\n",
    "                \"train_mAP_50\": train_metrics.coco_eval['segm'].stats[1], # train mAP@50\n",
    "                \"val_mAP_50\": val_metrics.coco_eval['segm'].stats[1], # val mAP@50\n",
    "                \"train_mAR_100\": train_metrics.coco_eval['segm'].stats[8], # train mAR@100\n",
    "                \"val_mAR_100\": val_metrics.coco_eval['segm'].stats[8], # val mAR@100\n",
    "                \"epoch\": epoch}, \n",
    "                checkpoint = checkpoint\n",
    "            )\n",
    "    \n",
    "    print(\"Tuning Trial Complete!\")\n",
    "\n",
    "\n",
    "def test_best_model(best_result, indices):\n",
    "    best_model = get_instance_segmentation_model(num_classes = 2) # background, chestnut bur\n",
    "\n",
    "    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "    best_model.to(device)\n",
    "\n",
    "    checkpoint_path = os.path.join(best_result.checkpoint.to_directory(), \"checkpoint.pt\")\n",
    "\n",
    "    model_state, _ = torch.load(checkpoint_path)\n",
    "    best_model.load_state_dict(model_state)\n",
    "\n",
    "    _, test_ds = load_data()\n",
    "    test_ds = Subset(test_ds, indices[-int(len(test_ds)*0.05):]) # last 5% of dataset for testing\n",
    "    test_dl = DataLoader(test_ds, batch_size = 1, shuffle = False, collate_fn = ChestnutBurSegmentation.collate_fn, num_workers=0, pin_memory=True)\n",
    "\n",
    "    _, test_results = engine.evaluate(best_model, test_dl, device, train_data_loader=None)\n",
    "\n",
    "    print(f'Best trial test set mAP_50: {test_results.coco_eval[\"segm\"].stats[1]} and mAR_100: {test_results.coco_eval[\"segm\"].stats[8]}')\n",
    "\n",
    "\n",
    "def trial_dirname_creator(trial):\n",
    "    return f\"train_MAVdroneDataset_{trial.trial_id}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "def main(num_samples, indices):\n",
    "    search_space = CS.ConfigurationSpace()\n",
    "    search_space.add_hyperparameter(\n",
    "        CS.Constant(\"epochs\", 10)\n",
    "    )\n",
    "    search_space.add_hyperparameter(\n",
    "        CS.UniformFloatHyperparameter(\"lr\", lower=0.00009, upper=0.05)\n",
    "    )\n",
    "    search_space.add_hyperparameter(\n",
    "        CS.UniformFloatHyperparameter(\"momentum\", lower=0.00001, upper=0.99)\n",
    "    )\n",
    "    search_space.add_hyperparameter(\n",
    "        CS.UniformFloatHyperparameter(\"weight_decay\", lower=0.00001, upper=0.99)\n",
    "    )\n",
    "    search_space.add_hyperparameter(\n",
    "        CS.CategoricalHyperparameter(\"batch_size\", choices=[2, 4, 8])\n",
    "    )\n",
    "\n",
    "    # Extract the integer value of epochs\n",
    "    max_epochs = search_space.get_hyperparameter(\"epochs\").default_value\n",
    "    \n",
    "    # Ensure max_epochs is an integer\n",
    "    max_epochs = int(max_epochs)\n",
    "\n",
    "    algo = TuneBOHB(\n",
    "        space=search_space,\n",
    "        metric=\"mAP_50\",\n",
    "        mode=\"max\",\n",
    "    )\n",
    "    algo = tune.search.ConcurrencyLimiter(algo, max_concurrent=4)\n",
    "    scheduler = HyperBandForBOHB(\n",
    "        time_attr=\"training_iteration\",\n",
    "        max_t=max_epochs,\n",
    "        reduction_factor=4,\n",
    "        stop_last_trials=False,\n",
    "    )\n",
    "\n",
    "    tuner = tune.Tuner(\n",
    "        tune.with_resources(\n",
    "            tune.with_parameters(train_ChestnutBurSegmentation, indices=indices),\n",
    "            resources = {\"cpu\": 48, \"gpu\": 1.0},\n",
    "        ),\n",
    "        run_config=train.RunConfig(\n",
    "            name=\"bohb_exp\",\n",
    "            storage_path='C:/Users/exx/Documents/GitHub/Savanna-Institute/Drone-based_Chestnut_Detection/ray_results',\n",
    "            stop={\"training_iteration\": max_epochs},\n",
    "        ),\n",
    "        tune_config = tune.TuneConfig(\n",
    "            metric = \"val_mAP_50\",\n",
    "            mode = \"max\",\n",
    "            search_alg = algo,\n",
    "            scheduler = scheduler,\n",
    "            num_samples = int(num_samples),\n",
    "            time_budget_s=600000,\n",
    "            trial_dirname_creator=trial_dirname_creator\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    results = tuner.fit()\n",
    "\n",
    "    best_result = results.get_best_result(metric = \"val_mAP_50\", mode = \"max\", scope = \"all\", filter_nan_and_inf=False)\n",
    "\n",
    "    print(\"Best trial config: {}\".format(best_result.config))\n",
    "    print(\"Best trial final training loss: {}\".format(best_result.metrics[\"train_loss\"]))\n",
    "    print(\"Best trial final validation loss: {}\".format(best_result.metrics[\"val_loss\"]))\n",
    "    print(\"Best trial final training mAP_50: {}\".format(best_result.metrics[\"train_mAP_50\"]))\n",
    "    print(\"Best trial final validation mAP_50: {}\".format(best_result.metrics[\"val_mAP_50\"]))\n",
    "    print(\"Best trial final training mAR_100: {}\".format(best_result.metrics[\"train_mAR_100\"]))\n",
    "    print(\"Best trial final validation mAR_100: {}\".format(best_result.metrics[\"val_mAR_100\"]))\n",
    "\n",
    "    test_best_model(best_result, indices)\n",
    "\n",
    "    return best_result\n",
    "\n",
    "if __name__ == \"__main__\": \n",
    "    best_trial = main(num_samples = 20, indices = indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = best_trial.config[\"batch_size\"]\n",
    "lr = best_trial.config[\"lr\"]\n",
    "momentum = best_trial.config[\"momentum\"]\n",
    "weight_decay = best_trial.config[\"weight_decay\"]\n",
    "\n",
    "# train on the GPU or on the CPU, if a GPU is not available\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "num_classes = 2 # (background = 0, chestnut bur = 1)\n",
    "\n",
    "# use our dataset and defined transformations\n",
    "train_ds = ChestnutBurSegmentation(image_dir, df, get_transform(train = True))\n",
    "val_ds = ChestnutBurSegmentation(image_dir, df, get_transform(train = False))\n",
    "\n",
    "train_ds = Subset(train_ds, indices[:-int(len(train_ds)*0.2)]) # first 80% of dataset for training\n",
    "val_ds = Subset(val_ds, indices[-int(len(train_ds)*0.2):-int(len(train_ds)*0.05)]) # next 15% of dataset for validation\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size = batch_size, shuffle = True, collate_fn = ChestnutBurSegmentation.collate_fn)\n",
    "valid_dl = DataLoader(val_ds, batch_size = 1, shuffle = False, collate_fn = ChestnutBurSegmentation.collate_fn)\n",
    "\n",
    "# get the model using our helper function\n",
    "model = get_instance_segmentation_model(num_classes)\n",
    "\n",
    "# move model to the right device\n",
    "model.to(device)\n",
    "\n",
    "# construct an optimizer\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(\n",
    "    params,\n",
    "    lr=lr,\n",
    "    momentum=momentum,\n",
    "    weight_decay=weight_decay\n",
    ")\n",
    "\n",
    "warmup_factor = 1.0 / 1000\n",
    "warmup_iters = min(1000, int(len(indices)*0.8) - 1)\n",
    "\n",
    "# construct a learning rate scheduler\n",
    "lr_scheduler = torch.optim.lr_scheduler.LinearLR(\n",
    "        optimizer, start_factor=warmup_factor, total_iters=warmup_iters\n",
    "    )\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # train for one epoch, printing every 10 iterations\n",
    "    train_logger, val_logger = engine.train_one_epoch(model, optimizer, train_dl, valid_dl, device, epoch, print_freq=10, scaler=None)\n",
    "    # update the learning rate\n",
    "    lr_scheduler.step()\n",
    "    # evaluate on the test dataset\n",
    "    train_performance, val_performance = engine.evaluate(model, valid_dl, device, train_dl)\n",
    "\n",
    "print(\"That's it!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model and weights to .pth\n",
    "torch.save(model.state_dict(), f\"C:/Users/exx/Documents/GitHub/Savanna-Institute/Drone-based_Chestnut_Detection/model_{time.strftime('%Y%m%d')}_{time.strftime('%H%M%S')}.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bohb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
